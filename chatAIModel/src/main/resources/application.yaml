server:
  port: 8888
spring:
  application:
    name: chat-ai
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        model: deepseek-r1:7b
        temperature: 0.8 # 模型温度，值越大，输出结果越随机
    openai:
      base-url: https://dashscope.aliyuncs.com/compatible-mode
      api-key: sk-71b61c28906841d3aa33fa4d5496e67b
      chat:
        options:
          model: qwen-max-0125 # 可选择的模型
  data:
    redis:
      host: 127.0.0.1
      port: 6379
      password: 123456



logging:
  level:
    org.springframework.ai.chat.client.advisor: debug
